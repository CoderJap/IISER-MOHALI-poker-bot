{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: treys in c:\\users\\jasje\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install treys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from enum import Enum, auto\n",
    "\n",
    "class Action(Enum):\n",
    "    FOLD = 0\n",
    "    CHECK = 1\n",
    "    CALL = 2\n",
    "    RAISE = 3\n",
    "    BET = 4\n",
    "\n",
    "class Player:\n",
    "    def __init__(self, id, stack):\n",
    "        self.id = id\n",
    "        self.stack = stack\n",
    "        self.hand = []\n",
    "        self.current_bet = 0\n",
    "        self.folded = False\n",
    "\n",
    "class TexasHoldEm:\n",
    "    def __init__(self, players, small_blind=10, big_blind=20):\n",
    "        self.players = players  # List of Player objects\n",
    "        self.small_blind = small_blind\n",
    "        self.big_blind = big_blind\n",
    "        self.deck = self.initialize_deck()\n",
    "        self.board = []  # Community cards\n",
    "        self.pot = 0\n",
    "        self.current_bet = 0\n",
    "        self.game_over = False\n",
    "        self.dealer_index = 0  # Index of the dealer in self.players\n",
    "        self.current_player_index = (self.dealer_index + 1) % len(self.players)  # Player to act\n",
    "        self.betting_round = 'pre-flop'  # Can be 'pre-flop', 'flop', 'turn', 'river'\n",
    "        self.round_bets = {}  # Tracks bets per player in the current round\n",
    "        self.last_raiser = None  # Tracks the last player who raised\n",
    "\n",
    "    def initialize_deck(self):\n",
    "        suits = ['H', 'D', 'C', 'S']\n",
    "        ranks = range(2, 15)  # 2-14 where 11-14 are J, Q, K, A\n",
    "        deck = [(rank, suit) for rank in ranks for suit in suits]\n",
    "        random.shuffle(deck)\n",
    "        return deck\n",
    "\n",
    "    def deal_hole_cards(self):\n",
    "        for player in self.players:\n",
    "            player.hand = [self.deck.pop(), self.deck.pop()]\n",
    "            player.current_bet = 0\n",
    "            player.folded = False\n",
    "        self.round_bets = {player.id: 0 for player in self.players}\n",
    "\n",
    "    def post_blinds(self):\n",
    "        small_blind_player = self.players[(self.dealer_index + 1) % len(self.players)]\n",
    "        big_blind_player = self.players[(self.dealer_index + 2) % len(self.players)]\n",
    "        \n",
    "        self._post_blind(small_blind_player, self.small_blind)\n",
    "        self._post_blind(big_blind_player, self.big_blind)\n",
    "        \n",
    "        self.current_bet = self.big_blind\n",
    "        self.last_raiser = big_blind_player.id\n",
    "\n",
    "        # Set current player to the one after the big blind\n",
    "        self.current_player_index = (self.dealer_index + 3) % len(self.players)\n",
    "\n",
    "    def _post_blind(self, player, amount):\n",
    "        player.stack -= amount\n",
    "        player.current_bet = amount\n",
    "        self.pot += amount\n",
    "        self.round_bets[player.id] = amount\n",
    "\n",
    "    def deal_flop(self):\n",
    "        self.deck.pop()  # Burn card\n",
    "        self.board.extend([self.deck.pop() for _ in range(3)])\n",
    "        self.betting_round = 'flop'\n",
    "        self.reset_bets()\n",
    "\n",
    "    def deal_turn(self):\n",
    "        self.deck.pop()  # Burn card\n",
    "        self.board.append(self.deck.pop())\n",
    "        self.betting_round = 'turn'\n",
    "        self.reset_bets()\n",
    "\n",
    "    def deal_river(self):\n",
    "        self.deck.pop()  # Burn card\n",
    "        self.board.append(self.deck.pop())\n",
    "        self.betting_round = 'river'\n",
    "        self.reset_bets()\n",
    "\n",
    "    def reset_bets(self):\n",
    "        self.current_bet = 0\n",
    "        for player in self.players:\n",
    "            player.current_bet = 0\n",
    "        self.round_bets = {player.id: 0 for player in self.players}\n",
    "        self.current_player_index = self.dealer_index  # Start with the player after the dealer\n",
    "        self.last_raiser = None\n",
    "\n",
    "    def get_current_player(self):\n",
    "        while True:\n",
    "            player = self.players[self.current_player_index]\n",
    "            if not player.folded:\n",
    "                return player\n",
    "            self.current_player_index = (self.current_player_index + 1) % len(self.players)\n",
    "\n",
    "    def get_available_actions(self, player):\n",
    "        if player.current_bet < self.current_bet:\n",
    "            # Player needs to call or fold\n",
    "            actions = [Action.FOLD, Action.CALL, Action.RAISE]\n",
    "        else:\n",
    "            # Player can check or bet/raise\n",
    "            if self.current_bet == 0:\n",
    "                actions = [Action.CHECK, Action.BET]\n",
    "            else:\n",
    "                actions = [Action.CHECK, Action.RAISE]\n",
    "        return actions\n",
    "\n",
    "    def execute_action(self, player, action, raise_amount=0):\n",
    "        if action == Action.FOLD:\n",
    "            self.handle_fold(player)\n",
    "        elif action == Action.CHECK:\n",
    "            self.handle_check(player)\n",
    "        elif action == Action.CALL:\n",
    "            self.handle_call(player)\n",
    "        elif action == Action.BET:\n",
    "            self.handle_bet(player, raise_amount)\n",
    "        elif action == Action.RAISE:\n",
    "            self.handle_raise(player, raise_amount)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action\")\n",
    "\n",
    "        # Move to the next player\n",
    "        self.current_player_index = (self.current_player_index + 1) % len(self.players)\n",
    "\n",
    "    def handle_fold(self, player):\n",
    "        player.folded = True\n",
    "        print(f\"Player {player.id} folds.\")\n",
    "\n",
    "    def handle_check(self, player):\n",
    "        print(f\"Player {player.id} checks.\")\n",
    "\n",
    "    def handle_call(self, player):\n",
    "        call_amount = self.current_bet - player.current_bet\n",
    "        player.stack -= call_amount\n",
    "        player.current_bet += call_amount\n",
    "        self.pot += call_amount\n",
    "        self.round_bets[player.id] += call_amount\n",
    "        print(f\"Player {player.id} calls {call_amount}.\")\n",
    "\n",
    "    def handle_bet(self, player, amount):\n",
    "        if amount <= 0 or amount > player.stack:\n",
    "            raise ValueError(\"Invalid bet amount\")\n",
    "        player.stack -= amount\n",
    "        player.current_bet += amount\n",
    "        self.current_bet = player.current_bet\n",
    "        self.pot += amount\n",
    "        self.round_bets[player.id] += amount\n",
    "        self.last_raiser = player.id\n",
    "        print(f\"Player {player.id} bets {amount}.\")\n",
    "\n",
    "    def handle_raise(self, player, amount):\n",
    "        if amount <= 0 or amount > player.stack:\n",
    "            raise ValueError(\"Invalid raise amount\")\n",
    "        call_amount = self.current_bet - player.current_bet\n",
    "        total_amount = call_amount + amount\n",
    "        player.stack -= total_amount\n",
    "        player.current_bet += total_amount\n",
    "        self.current_bet = player.current_bet\n",
    "        self.pot += total_amount\n",
    "        self.round_bets[player.id] += total_amount\n",
    "        self.last_raiser = player.id\n",
    "        print(f\"Player {player.id} raises by {amount} to {player.current_bet}.\")\n",
    "\n",
    "    def is_round_over(self):\n",
    "        # The betting round is over when all players have either called the current bet or folded\n",
    "        active_players = [p for p in self.players if not p.folded]\n",
    "        if len(active_players) == 1:\n",
    "            return True  # Only one player remains\n",
    "        for player in active_players:\n",
    "            if player.id == self.last_raiser:\n",
    "                continue  # Skip the last raiser\n",
    "            if player.current_bet != self.current_bet:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def progress_round(self):\n",
    "        if self.betting_round == 'pre-flop':\n",
    "            self.deal_flop()\n",
    "        elif self.betting_round == 'flop':\n",
    "            self.deal_turn()\n",
    "        elif self.betting_round == 'turn':\n",
    "            self.deal_river()\n",
    "        elif self.betting_round == 'river':\n",
    "            self.game_over = True  # Proceed to showdown\n",
    "        else:\n",
    "            raise ValueError(\"Invalid betting round\")\n",
    "\n",
    "    def is_game_over(self):\n",
    "        # The game is over if only one player remains or all betting rounds are complete\n",
    "        active_players = [p for p in self.players if not p.folded]\n",
    "        if len(active_players) == 1:\n",
    "            return True\n",
    "        return self.game_over\n",
    "\n",
    "    def determine_winner(self):\n",
    "        # If only one player remains\n",
    "        active_players = [p for p in self.players if not p.folded]\n",
    "        if len(active_players) == 1:\n",
    "            winner = active_players[0]\n",
    "            winner.stack += self.pot\n",
    "            print(f\"Player {winner.id} wins the pot of {self.pot} by default.\")\n",
    "            self.pot = 0\n",
    "            return\n",
    "\n",
    "        # Showdown: compare hands\n",
    "        from treys import Evaluator, Card\n",
    "        evaluator = Evaluator()\n",
    "        best_rank = None\n",
    "        winners = []\n",
    "        for player in active_players:\n",
    "            hand = [Card.new(f\"{self.rank_to_str(rank)}{suit}\") for rank, suit in player.hand]\n",
    "            board = [Card.new(f\"{self.rank_to_str(rank)}{suit}\") for rank, suit in self.board]\n",
    "            rank = evaluator.evaluate(board, hand)\n",
    "            if best_rank is None or rank < best_rank:\n",
    "                best_rank = rank\n",
    "                winners = [player]\n",
    "            elif rank == best_rank:\n",
    "                winners.append(player)\n",
    "        # Split the pot among winners\n",
    "        split_pot = self.pot / len(winners)\n",
    "        for winner in winners:\n",
    "            winner.stack += split_pot\n",
    "            print(f\"Player {winner.id} wins {split_pot} from the pot.\")\n",
    "        self.pot = 0\n",
    "\n",
    "    def rank_to_str(self, rank):\n",
    "        if rank == 14:\n",
    "            return 'A'\n",
    "        elif rank == 13:\n",
    "            return 'K'\n",
    "        elif rank == 12:\n",
    "            return 'Q'\n",
    "        elif rank == 11:\n",
    "            return 'J'\n",
    "        elif rank == 10:\n",
    "            return 'T'\n",
    "        else:\n",
    "            return str(rank)\n",
    "\n",
    "    def get_reward(self, player):\n",
    "        # Define reward as the change in the player's stack\n",
    "        return player.stack - 1000  # Assuming initial stack is 1000\n",
    "\n",
    "    # Additional helper methods can be added as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeliefState:\n",
    "    def __init__(self, observed_actions, public_cards, pot_size=0):\n",
    "        self.observed_actions = observed_actions  # Sequence of actions taken\n",
    "        self.public_cards = public_cards          # Community cards revealed\n",
    "        self.private_cards = None                 # The AI's own hand\n",
    "        self.pot_size = pot_size                  # Pot size\n",
    "\n",
    "    def update(self, action, new_public_cards=None, pot_size=None):\n",
    "        self.observed_actions.append(action)\n",
    "        if new_public_cards is not None:\n",
    "            self.public_cards = new_public_cards\n",
    "        if pot_size is not None:\n",
    "            self.pot_size = pot_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)  # Output a scalar value\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_size, action_space):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, action_space)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.Softmax(dim=-1)(self.fc(x))\n",
    "\n",
    "\n",
    "\n",
    "MAX_FEATURE_LENGTH = 25  # Adjust this value based on your game dynamics\n",
    "\n",
    "def extract_features(belief_state):\n",
    "    # Convert actions to numerical representation\n",
    "    action_features = [action.value for action in belief_state.observed_actions]\n",
    "    \n",
    "    # Flatten public cards\n",
    "    public_card_features = [rank for (rank, suit) in belief_state.public_cards]\n",
    "    \n",
    "    # Combine features\n",
    "    features = action_features + public_card_features\n",
    "    \n",
    "    # Pad or truncate to fixed size\n",
    "    features = features[:MAX_FEATURE_LENGTH] + [0] * max(0, MAX_FEATURE_LENGTH - len(features))\n",
    "    \n",
    "    return torch.tensor(features, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global dictionary to store CFRNodes\n",
    "cfr_nodes = {}\n",
    "\n",
    "class CFRNode:\n",
    "    def __init__(self, info_set, actions):\n",
    "        self.info_set = info_set\n",
    "        self.actions = actions\n",
    "        self.regret_sum = {action: 0.0 for action in actions}\n",
    "        self.strategy = {action: 1.0 / len(actions) for action in actions}\n",
    "        self.strategy_sum = {action: 0.0 for action in actions}\n",
    "\n",
    "    def get_strategy(self):\n",
    "        normalizing_sum = 0.0\n",
    "        for action in self.actions:\n",
    "            self.strategy[action] = max(self.regret_sum[action], 0.0)\n",
    "            normalizing_sum += self.strategy[action]\n",
    "        if normalizing_sum > 0:\n",
    "            for action in self.actions:\n",
    "                self.strategy[action] /= normalizing_sum\n",
    "        else:\n",
    "            for action in self.actions:\n",
    "                self.strategy[action] = 1.0 / len(self.actions)\n",
    "        # Update strategy sum for averaging\n",
    "        for action in self.actions:\n",
    "            self.strategy_sum[action] += self.strategy[action]\n",
    "        return self.strategy\n",
    "\n",
    "def get_or_create_cfr_node(info_set, actions):\n",
    "    if info_set not in cfr_nodes:\n",
    "        cfr_nodes[info_set] = CFRNode(info_set, actions)\n",
    "    return cfr_nodes[info_set]\n",
    "\n",
    "def cfr(node, p0, p1):\n",
    "    if node.is_terminal():\n",
    "        return node.utility()\n",
    "    info_set = node.get_info_set()\n",
    "    actions = node.get_available_actions()\n",
    "    cfr_node = get_or_create_cfr_node(info_set, actions)\n",
    "    strategy = cfr_node.get_strategy()\n",
    "    util = {}\n",
    "    node_util = 0\n",
    "    for action in actions:\n",
    "        next_node = node.take_action(action)\n",
    "        if node.current_player == 0:\n",
    "            util[action] = -cfr(next_node, p0 * strategy[action], p1)\n",
    "        else:\n",
    "            util[action] = -cfr(next_node, p0, p1 * strategy[action])\n",
    "        node_util += strategy[action] * util[action]\n",
    "    for action in actions:\n",
    "        regret = util[action] - node_util\n",
    "        if node.current_player == 0:\n",
    "            cfr_node.regret_sum[action] += p1 * regret\n",
    "        else:\n",
    "            cfr_node.regret_sum[action] += p0 * regret\n",
    "    return node_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_players = 2  # Since we're working with a two-player game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GameNode:\n",
    "#     def __init__(self, current_player, hands, board, history, num_players=2, \n",
    "#                  pot=0, player_stacks=None, player_bets=None, current_bet=0, \n",
    "#                  folded_players=None, betting_round='pre-flop', last_raiser=None):\n",
    "#         self.current_player = current_player  # ID of the current player\n",
    "#         self.hands = hands  # Dictionary mapping player IDs to their hands\n",
    "#         self.board = board  # Community cards\n",
    "#         self.history = history  # List of actions taken\n",
    "#         self.num_players = num_players  # Total number of players\n",
    "#         self.pot = pot  # Current size of the pot\n",
    "#         self.player_stacks = player_stacks if player_stacks is not None else {player_id: 1000 for player_id in hands}\n",
    "#         self.player_bets = player_bets if player_bets is not None else {player_id: 0 for player_id in hands}\n",
    "#         self.current_bet = current_bet  # Highest bet in the current betting round\n",
    "#         self.folded_players = folded_players if folded_players is not None else set()  # Players who have folded\n",
    "#         self.betting_round = betting_round  # Current betting round ('pre-flop', 'flop', 'turn', 'river')\n",
    "#         self.last_raiser = last_raiser  # ID of the last player who raised\n",
    "\n",
    "    \n",
    "#     def is_terminal(self):\n",
    "#         # Implement logic to determine if the game has ended\n",
    "#         pass\n",
    "    \n",
    "#     def utility(self):\n",
    "#         # Calculate the utility (payoff) for the current player\n",
    "#         pass\n",
    "    \n",
    "#     def get_info_set(self):\n",
    "#         # As defined earlier\n",
    "#         player_hand = self.hands[self.current_player]\n",
    "#         public_cards = self.board\n",
    "#         observed_actions = self.history\n",
    "#         info_set = (\n",
    "#             tuple(sorted(player_hand)),\n",
    "#             tuple(sorted(public_cards)),\n",
    "#             tuple(observed_actions)\n",
    "#         )\n",
    "#         return info_set\n",
    "    \n",
    "#     def get_available_actions(self):\n",
    "#         # Return a list of possible actions at this node\n",
    "#         return [Action.FOLD, Action.CALL, Action.RAISE]  # Example actions\n",
    "\n",
    "\n",
    "#     def take_action(self, action, amount=0):\n",
    "#         new_history = self.history + [action]\n",
    "#         new_hands = self.hands.copy()\n",
    "#         new_board = self.board.copy()\n",
    "#         new_pot = self.pot\n",
    "#         new_player_stacks = self.player_stacks.copy()\n",
    "#         new_player_bets = self.player_bets.copy()\n",
    "#         new_folded_players = self.folded_players.copy()\n",
    "#         new_current_bet = self.current_bet\n",
    "#         new_last_raiser = self.last_raiser\n",
    "#         new_betting_round = self.betting_round\n",
    "\n",
    "#         current_player_id = self.current_player\n",
    "\n",
    "#         if action == Action.FOLD:\n",
    "#             new_folded_players.add(current_player_id)\n",
    "#         elif action == Action.CALL:\n",
    "#             call_amount = new_current_bet - new_player_bets[current_player_id]\n",
    "#             if call_amount > new_player_stacks[current_player_id]:\n",
    "#                 call_amount = new_player_stacks[current_player_id]  # All-in\n",
    "#             new_player_stacks[current_player_id] -= call_amount\n",
    "#             new_player_bets[current_player_id] += call_amount\n",
    "#             new_pot += call_amount\n",
    "#         elif action == Action.RAISE:\n",
    "#             raise_amount = amount\n",
    "#             total_bet = new_current_bet + raise_amount\n",
    "#             bet_amount = total_bet - new_player_bets[current_player_id]\n",
    "#             if bet_amount > new_player_stacks[current_player_id]:\n",
    "#                 bet_amount = new_player_stacks[current_player_id]  # All-in\n",
    "#                 total_bet = new_player_bets[current_player_id] + bet_amount\n",
    "#             new_player_stacks[current_player_id] -= bet_amount\n",
    "#             new_player_bets[current_player_id] += bet_amount\n",
    "#             new_pot += bet_amount\n",
    "#             new_current_bet = total_bet\n",
    "#             new_last_raiser = current_player_id\n",
    "#         elif action == Action.CHECK:\n",
    "#             pass  # No changes needed for check\n",
    "#         elif action == Action.BET:\n",
    "#             bet_amount = amount\n",
    "#             if bet_amount > new_player_stacks[current_player_id]:\n",
    "#                 bet_amount = new_player_stacks[current_player_id]  # All-in\n",
    "#             new_player_stacks[current_player_id] -= bet_amount\n",
    "#             new_player_bets[current_player_id] += bet_amount\n",
    "#             new_pot += bet_amount\n",
    "#             new_current_bet = new_player_bets[current_player_id]\n",
    "#             new_last_raiser = current_player_id\n",
    "#         else:\n",
    "#             raise ValueError(\"Invalid action\")\n",
    "\n",
    "#         # Determine the next player\n",
    "#         next_player = (self.current_player + 1) % self.num_players\n",
    "#         while next_player in new_folded_players:\n",
    "#             next_player = (next_player + 1) % self.num_players\n",
    "#             if next_player == self.current_player:\n",
    "#                 break  # All other players have folded\n",
    "\n",
    "#         # Create a new GameNode with updated state\n",
    "#         new_node = GameNode(\n",
    "#             current_player=next_player,\n",
    "#             hands=new_hands,\n",
    "#             board=new_board,\n",
    "#             history=new_history,\n",
    "#             num_players=self.num_players,\n",
    "#             pot=new_pot,\n",
    "#             player_stacks=new_player_stacks,\n",
    "#             player_bets=new_player_bets,\n",
    "#             current_bet=new_current_bet,\n",
    "#             folded_players=new_folded_players,\n",
    "#             betting_round=new_betting_round,\n",
    "#             last_raiser=new_last_raiser\n",
    "#         )\n",
    "\n",
    "#         # Update betting round if needed\n",
    "#         if self.should_progress_round(new_node):\n",
    "#             new_node.progress_round()\n",
    "\n",
    "#         return new_node\n",
    "    \n",
    "#     def should_progress_round(self, node):\n",
    "#         active_players = [p for p in range(self.num_players) if p not in node.folded_players]\n",
    "#         # If only one player remains, the game ends\n",
    "#         if len(active_players) <= 1:\n",
    "#             return False\n",
    "#         # If all active players have matched the current bet or are all-in\n",
    "#         for player_id in active_players:\n",
    "#             player_bet = node.player_bets[player_id]\n",
    "#             if player_bet != node.current_bet and node.player_stacks[player_id] > 0:\n",
    "#                 return False\n",
    "#         return True\n",
    "    \n",
    "#     def progress_round(self):\n",
    "#         self.player_bets = {player_id: 0 for player_id in self.player_bets}\n",
    "#         self.current_bet = 0\n",
    "#         self.last_raiser = None\n",
    "\n",
    "#         if self.betting_round == 'pre-flop':\n",
    "#             self.deal_flop()\n",
    "#             self.betting_round = 'flop'\n",
    "#         elif self.betting_round == 'flop':\n",
    "#             self.deal_turn()\n",
    "#             self.betting_round = 'turn'\n",
    "#         elif self.betting_round == 'turn':\n",
    "#             self.deal_river()\n",
    "#             self.betting_round = 'river'\n",
    "#         elif self.betting_round == 'river':\n",
    "#             self.betting_round = 'showdown'\n",
    "#         else:\n",
    "#             pass  # Game is over\n",
    "\n",
    "#     def deal_flop(self):\n",
    "#         # Assuming self.deck is managed elsewhere\n",
    "#         self.board.extend([self.deck.pop() for _ in range(3)])\n",
    "\n",
    "#     def deal_turn(self):\n",
    "#         self.board.append(self.deck.pop())\n",
    "\n",
    "#     def deal_river(self):\n",
    "#         self.board.append(self.deck.pop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameNode:\n",
    "    def __init__(self, current_player, hands, board, history, num_players=2, \n",
    "                 pot=0, player_stacks=None, player_bets=None, current_bet=0, \n",
    "                 folded_players=None, betting_round='pre-flop', last_raiser=None, deck=None):\n",
    "        self.current_player = current_player  # ID of the current player\n",
    "        self.hands = hands  # Dictionary mapping player IDs to their hands\n",
    "        self.board = board  # Community cards\n",
    "        self.history = history  # List of actions taken\n",
    "        self.num_players = num_players  # Total number of players\n",
    "        self.pot = pot  # Current size of the pot\n",
    "        self.player_stacks = player_stacks if player_stacks is not None else {player_id: 1000 for player_id in hands}\n",
    "        self.player_bets = player_bets if player_bets is not None else {player_id: 0 for player_id in hands}\n",
    "        self.current_bet = current_bet  # Highest bet in the current betting round\n",
    "        self.folded_players = folded_players if folded_players is not None else set()  # Players who have folded\n",
    "        self.betting_round = betting_round  # Current betting round ('pre-flop', 'flop', 'turn', 'river', 'showdown')\n",
    "        self.last_raiser = last_raiser  # ID of the last player who raised\n",
    "        self.deck = deck if deck is not None else self.initialize_deck()  # Remaining cards in the deck\n",
    "\n",
    "    def initialize_deck(self):\n",
    "        suits = ['h', 'd', 'c', 's']\n",
    "        ranks = range(2, 15)  # 2-14 where 11-14 are J, Q, K, A\n",
    "        deck = [(rank, suit) for rank in ranks for suit in suits]\n",
    "        random.shuffle(deck)\n",
    "        return deck\n",
    "\n",
    "    def is_terminal(self):\n",
    "        active_players = [p for p in range(self.num_players) if p not in self.folded_players]\n",
    "        # Game ends if only one player remains or after showdown\n",
    "        if len(active_players) <= 1 or self.betting_round == 'showdown':\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def utility(self):\n",
    "        if not self.is_terminal():\n",
    "            return 0  # Utility is zero if the game is not over\n",
    "\n",
    "        active_players = [p for p in range(self.num_players) if p not in self.folded_players]\n",
    "        if len(active_players) == 1:\n",
    "            # Only one player left; they win the pot\n",
    "            winner = active_players[0]\n",
    "            if self.current_player == winner:\n",
    "                return self.pot\n",
    "            else:\n",
    "                return -self.pot\n",
    "        else:\n",
    "            # Showdown: compare hands\n",
    "            hand_strengths = {p: self.evaluate_hand(p) for p in active_players}\n",
    "            best_strength = min(hand_strengths.values())\n",
    "            winners = [p for p, strength in hand_strengths.items() if strength == best_strength]\n",
    "            if self.current_player in winners:\n",
    "                # Split the pot among winners\n",
    "                return self.pot / len(winners)\n",
    "            else:\n",
    "                return -self.pot / len(winners)\n",
    "\n",
    "    def evaluate_hand(self, player_id):\n",
    "        from treys import Evaluator, Card\n",
    "        evaluator = Evaluator()\n",
    "        player_hand = self.hands[player_id]\n",
    "        board = self.board\n",
    "        # Convert to treys Card objects\n",
    "        player_cards = [Card.new(f\"{self.rank_to_str(rank)}{suit}\") for rank, suit in player_hand]\n",
    "        board_cards = [Card.new(f\"{self.rank_to_str(rank)}{suit}\") for rank, suit in board]\n",
    "        rank = evaluator.evaluate(board_cards, player_cards)\n",
    "        return rank  # Lower rank means a better hand\n",
    "\n",
    "    def rank_to_str(self, rank):\n",
    "        rank_dict = {14: 'A', 13: 'K', 12: 'Q', 11: 'J', 10: 'T'}\n",
    "        return rank_dict.get(rank, str(rank))\n",
    "\n",
    "    def get_info_set(self):\n",
    "        player_hand = self.hands[self.current_player]\n",
    "        public_cards = self.board\n",
    "        observed_actions = self.history\n",
    "        info_set = (\n",
    "            tuple(sorted(player_hand)),\n",
    "            tuple(sorted(public_cards)),\n",
    "            tuple(observed_actions)\n",
    "        )\n",
    "        return info_set\n",
    "\n",
    "    def get_available_actions(self):\n",
    "        if self.current_bet > self.player_bets[self.current_player]:\n",
    "            # Player needs to call, raise, or fold\n",
    "            return [Action.FOLD, Action.CALL, Action.RAISE]\n",
    "        else:\n",
    "            # Player can check or bet/raise\n",
    "            if self.current_bet == 0:\n",
    "                return [Action.CHECK, Action.BET]\n",
    "            else:\n",
    "                return [Action.CHECK, Action.RAISE]\n",
    "\n",
    "    def take_action(self, action, amount=0):\n",
    "        new_history = self.history + [action]\n",
    "        new_hands = self.hands.copy()\n",
    "        new_board = self.board.copy()\n",
    "        new_pot = self.pot\n",
    "        new_player_stacks = self.player_stacks.copy()\n",
    "        new_player_bets = self.player_bets.copy()\n",
    "        new_folded_players = self.folded_players.copy()\n",
    "        new_current_bet = self.current_bet\n",
    "        new_last_raiser = self.last_raiser\n",
    "        new_betting_round = self.betting_round\n",
    "        new_deck = self.deck.copy()\n",
    "\n",
    "        current_player_id = self.current_player\n",
    "\n",
    "        if action == Action.FOLD:\n",
    "            new_folded_players.add(current_player_id)\n",
    "        elif action == Action.CALL:\n",
    "            call_amount = new_current_bet - new_player_bets[current_player_id]\n",
    "            available_stack = new_player_stacks[current_player_id]\n",
    "            actual_call = min(call_amount, available_stack)\n",
    "            new_player_stacks[current_player_id] -= actual_call\n",
    "            new_player_bets[current_player_id] += actual_call\n",
    "            new_pot += actual_call\n",
    "        elif action == Action.RAISE:\n",
    "            raise_amount = amount\n",
    "            total_bet = new_current_bet + raise_amount\n",
    "            bet_amount = total_bet - new_player_bets[current_player_id]\n",
    "            available_stack = new_player_stacks[current_player_id]\n",
    "            actual_bet = min(bet_amount, available_stack)\n",
    "            new_player_stacks[current_player_id] -= actual_bet\n",
    "            new_player_bets[current_player_id] += actual_bet\n",
    "            new_pot += actual_bet\n",
    "            new_current_bet = new_player_bets[current_player_id]\n",
    "            new_last_raiser = current_player_id\n",
    "        elif action == Action.CHECK:\n",
    "            pass  # No action needed\n",
    "        elif action == Action.BET:\n",
    "            bet_amount = amount\n",
    "            available_stack = new_player_stacks[current_player_id]\n",
    "            actual_bet = min(bet_amount, available_stack)\n",
    "            new_player_stacks[current_player_id] -= actual_bet\n",
    "            new_player_bets[current_player_id] += actual_bet\n",
    "            new_pot += actual_bet\n",
    "            new_current_bet = new_player_bets[current_player_id]\n",
    "            new_last_raiser = current_player_id\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action\")\n",
    "\n",
    "        # Determine the next player\n",
    "        next_player = (self.current_player + 1) % self.num_players\n",
    "        while next_player in new_folded_players:\n",
    "            next_player = (next_player + 1) % self.num_players\n",
    "            if next_player == self.current_player:\n",
    "                break  # All other players have folded\n",
    "\n",
    "        # Create a new GameNode with updated state\n",
    "        new_node = GameNode(\n",
    "            current_player=next_player,\n",
    "            hands=new_hands,\n",
    "            board=new_board,\n",
    "            history=new_history,\n",
    "            num_players=self.num_players,\n",
    "            pot=new_pot,\n",
    "            player_stacks=new_player_stacks,\n",
    "            player_bets=new_player_bets,\n",
    "            current_bet=new_current_bet,\n",
    "            folded_players=new_folded_players,\n",
    "            betting_round=new_betting_round,\n",
    "            last_raiser=new_last_raiser,\n",
    "            deck=new_deck\n",
    "        )\n",
    "\n",
    "        # Update betting round if needed\n",
    "        if self.should_progress_round(new_node):\n",
    "            new_node.progress_round()\n",
    "\n",
    "        return new_node\n",
    "\n",
    "    def should_progress_round(self, node):\n",
    "        active_players = [p for p in range(self.num_players) if p not in node.folded_players]\n",
    "        if len(active_players) <= 1:\n",
    "            return True  # Only one player remains\n",
    "        # Check if all active players have matched the current bet or are all-in\n",
    "        for player_id in active_players:\n",
    "            if node.player_stacks[player_id] > 0 and node.player_bets[player_id] != node.current_bet:\n",
    "                return False\n",
    "        if node.last_raiser == node.current_player:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def progress_round(self):\n",
    "        # Reset player bets for the new round\n",
    "        self.player_bets = {player_id: 0 for player_id in self.player_bets}\n",
    "        self.current_bet = 0\n",
    "        self.last_raiser = None\n",
    "\n",
    "        if self.betting_round == 'pre-flop':\n",
    "            self.deal_flop()\n",
    "            self.betting_round = 'flop'\n",
    "        elif self.betting_round == 'flop':\n",
    "            self.deal_turn()\n",
    "            self.betting_round = 'turn'\n",
    "        elif self.betting_round == 'turn':\n",
    "            self.deal_river()\n",
    "            self.betting_round = 'river'\n",
    "        elif self.betting_round == 'river':\n",
    "            self.betting_round = 'showdown'\n",
    "        else:\n",
    "            pass  # Game is over\n",
    "\n",
    "    def deal_flop(self):\n",
    "        # Burn a card\n",
    "        self.deck.pop()\n",
    "        # Deal three community cards\n",
    "        self.board.extend([self.deck.pop() for _ in range(3)])\n",
    "\n",
    "    def deal_turn(self):\n",
    "        # Burn a card\n",
    "        self.deck.pop()\n",
    "        # Deal one community card\n",
    "        self.board.append(self.deck.pop())\n",
    "\n",
    "    def deal_river(self):\n",
    "        # Burn a card\n",
    "        self.deck.pop()\n",
    "        # Deal one community card\n",
    "        self.board.append(self.deck.pop())\n",
    "\n",
    "\n",
    "\n",
    "hands = {\n",
    "    0: [(14, 'h'), (13, 'd')],  # Player 0's hand\n",
    "    1: [(12, 's'), (11, 'c')]   # Player 1's hand\n",
    "}\n",
    "\n",
    "# Create the root game node\n",
    "root_node = GameNode(\n",
    "    current_player=0,\n",
    "    hands=hands,\n",
    "    board=[],\n",
    "    history=[],\n",
    "    num_players=2\n",
    ")\n",
    "\n",
    "# Player 0 takes an action\n",
    "next_node = root_node.take_action(Action.CALL)\n",
    "\n",
    "# Player 1 takes an action\n",
    "next_node = next_node.take_action(Action.CHECK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_net = ValueNetwork(input_size=MAX_FEATURE_LENGTH)\n",
    "# policy_net = PolicyNetwork(input_size=MAX_FEATURE_LENGTH, action_space=len(Action))\n",
    "# value_optimizer = optim.Adam(value_net.parameters(), lr=1e-4)\n",
    "# policy_optimizer = optim.Adam(policy_net.parameters(), lr=1e-4)\n",
    "\n",
    "# NUM_EPISODES = 500\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from enum import Enum, auto\n",
    "\n",
    "# # Define sample_action function\n",
    "# def sample_action(action_probs):\n",
    "#     \"\"\"\n",
    "#     Samples an action from the given action probabilities.\n",
    "\n",
    "#     Args:\n",
    "#         action_probs (torch.Tensor): A tensor containing the probabilities for each action.\n",
    "\n",
    "#     Returns:\n",
    "#         Action: The selected action.\n",
    "#     \"\"\"\n",
    "#     # Ensure action_probs is a 1D tensor\n",
    "#     if action_probs.dim() > 1:\n",
    "#         action_probs = action_probs.squeeze()\n",
    "\n",
    "#     # Sample an action index based on the probabilities\n",
    "#     action_index = torch.multinomial(action_probs, num_samples=1).item()\n",
    "\n",
    "#     # Map the index to an action\n",
    "#     action_list = list(Action)\n",
    "#     selected_action = action_list[action_index]\n",
    "\n",
    "#     return selected_action\n",
    "\n",
    "# # Initialize neural networks and optimizers\n",
    "# value_net = ValueNetwork(input_size=MAX_FEATURE_LENGTH)\n",
    "# policy_net = PolicyNetwork(input_size=MAX_FEATURE_LENGTH, action_space=len(Action))\n",
    "# value_optimizer = optim.Adam(value_net.parameters(), lr=1e-4)\n",
    "# policy_optimizer = optim.Adam(policy_net.parameters(), lr=1e-4)\n",
    "\n",
    "# # Training loop\n",
    "# for episode in range(NUM_EPISODES):\n",
    "#     # Initialize players\n",
    "#     players = [Player(id=0, stack=1000), Player(id=1, stack=1000)]\n",
    "    \n",
    "#     # Initialize the game\n",
    "#     game = TexasHoldEm(players)\n",
    "#     game.deal_hole_cards()\n",
    "    \n",
    "#     # Initialize belief states for each player\n",
    "#     belief_states = {player.id: BeliefState(observed_actions=[], public_cards=game.board) for player in players}\n",
    "    \n",
    "#     done = False\n",
    "#     experiences = []  # To store experiences for training\n",
    "    \n",
    "#     while not done:\n",
    "#         current_player = game.get_current_player()\n",
    "#         belief_state = belief_states[current_player.id]\n",
    "        \n",
    "#         # Extract features\n",
    "#         features = extract_features(belief_state)\n",
    "        \n",
    "#         # Get action probabilities from the policy network\n",
    "#         action_probs = policy_net(features)\n",
    "        \n",
    "#         # Choose an action\n",
    "#         action = sample_action(action_probs)\n",
    "        \n",
    "#         # Execute the action\n",
    "#         game.execute_action(current_player, action)\n",
    "        \n",
    "#         # Get reward (to be defined based on your reward structure)\n",
    "#         reward = game.get_reward(current_player)\n",
    "        \n",
    "#         # Record experience\n",
    "#         experiences.append((features, action, reward))\n",
    "        \n",
    "#         # Update belief states for all players\n",
    "#         for player in players:\n",
    "#             belief_states[player.id].update(action, new_public_cards=game.board)\n",
    "        \n",
    "#         # Check for end of round/game\n",
    "#         if game.is_round_over():\n",
    "#             game.progress_round()\n",
    "#         if game.is_game_over():\n",
    "#             game.determine_winner()\n",
    "#             done = True  # End the game loop\n",
    "    \n",
    "#     # After the game, update the networks using collected experiences\n",
    "\n",
    "#     # Step 1: Prepare the training data\n",
    "#     states = torch.stack([exp[0] for exp in experiences])  # Features are tensors\n",
    "#     actions = [exp[1] for exp in experiences]              # Actions are enums\n",
    "#     rewards = [exp[2] for exp in experiences]              # Rewards are scalars\n",
    "\n",
    "#     # Step 2: Convert actions to indices\n",
    "#     action_to_index = {action: idx for idx, action in enumerate(Action)}\n",
    "#     action_indices = torch.tensor([action_to_index[action] for action in actions], dtype=torch.long)\n",
    "\n",
    "#     # Step 3: Compute value targets (discounted cumulative rewards)\n",
    "#     rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "#     gamma = 1.0  # No discounting\n",
    "#     returns = []\n",
    "#     R = 0\n",
    "#     for r in reversed(rewards):\n",
    "#         R = r + gamma * R\n",
    "#         returns.insert(0, R)\n",
    "#     value_targets = torch.tensor(returns, dtype=torch.float32)\n",
    "\n",
    "#     # Step 4: Compute value loss\n",
    "#     value_predictions = value_net(states).squeeze()\n",
    "#     value_loss_fn = nn.MSELoss()\n",
    "#     value_loss = value_loss_fn(value_predictions, value_targets)\n",
    "\n",
    "#     # Step 5: Compute policy loss\n",
    "#     policy_outputs = policy_net(states)  # Shape: (batch_size, num_actions)\n",
    "#     action_probs = policy_outputs.gather(1, action_indices.unsqueeze(1)).squeeze()\n",
    "#     log_probs = torch.log(action_probs + 1e-10)\n",
    "#     with torch.no_grad():\n",
    "#         advantages = value_targets - value_predictions.detach()\n",
    "#     policy_loss = - (log_probs * advantages).mean()\n",
    "\n",
    "#     # Step 6: Update the networks\n",
    "#     # Update value network\n",
    "#     value_optimizer.zero_grad()\n",
    "#     value_loss.backward()\n",
    "#     value_optimizer.step()\n",
    "\n",
    "#     # Update policy network\n",
    "#     policy_optimizer.zero_grad()\n",
    "#     policy_loss.backward()\n",
    "#     policy_optimizer.step()\n",
    "    \n",
    "#     # Compute entropy of the policy\n",
    "#     entropy = - (policy_outputs * torch.log(policy_outputs + 1e-10)).sum(dim=1).mean()\n",
    "\n",
    "#     # Add entropy regularization to the policy loss\n",
    "#     entropy_coef = 0.01  # Adjust as needed\n",
    "#     policy_loss = policy_loss - entropy_coef * entropy\n",
    "    \n",
    "#     # Extract CFR strategies and values\n",
    "#     cfr_strategies = torch.stack([exp[2] for exp in experiences])  # CFR strategies\n",
    "#     cfr_values = torch.tensor([exp[3] for exp in experiences], dtype=torch.float32)  # CFR values\n",
    "\n",
    "#     # Value Loss\n",
    "#     value_predictions = value_net(states).squeeze()\n",
    "#     value_loss_fn = nn.MSELoss()\n",
    "#     value_loss = value_loss_fn(value_predictions, cfr_values)\n",
    "\n",
    "#     # Policy Loss\n",
    "#     policy_outputs = policy_net(states)\n",
    "#     policy_loss_fn = nn.CrossEntropyLoss()\n",
    "#     policy_loss = policy_loss_fn(policy_outputs, cfr_strategies.argmax(dim=1))\n",
    "\n",
    "\n",
    "\n",
    "#     # Optionally, print progress\n",
    "#     if (episode + 1) % 100 == 0:\n",
    "#         print(f\"Completed episode {episode + 1}/{NUM_EPISODES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "MAX_FEATURE_LENGTH = 25\n",
    "\n",
    "# Define ValueNetwork\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)  # Output a single value\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Define PolicyNetwork\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_size, action_space):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, action_space)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return self.softmax(x)\n",
    "    \n",
    "# Initialize neural networks and optimizers\n",
    "value_net = ValueNetwork(input_size=MAX_FEATURE_LENGTH)\n",
    "policy_net = PolicyNetwork(input_size=MAX_FEATURE_LENGTH, action_space=len(Action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, id, stack):\n",
    "        self.id = id\n",
    "        self.stack = stack  # Total chips the player has\n",
    "        self.hand = []      # The player's hole cards\n",
    "        self.current_bet = 0\n",
    "        self.folded = False\n",
    "\n",
    "    def reset_for_new_hand(self):\n",
    "        self.hand = []\n",
    "        self.current_bet = 0\n",
    "        self.folded = False\n",
    "\n",
    "import random\n",
    "from enum import Enum\n",
    "\n",
    "class TexasHoldEm:\n",
    "    def __init__(self, players, small_blind=10, big_blind=20):\n",
    "        self.players = players\n",
    "        self.small_blind = small_blind\n",
    "        self.big_blind = big_blind\n",
    "        self.deck = self.initialize_deck()\n",
    "        self.board = []  # Community cards\n",
    "        self.pot = 0\n",
    "        self.current_bet = 0\n",
    "        self.game_over = False\n",
    "        self.dealer_index = 0\n",
    "        self.current_player_index = (self.dealer_index + 1) % len(self.players)\n",
    "        self.betting_round = 'pre-flop'\n",
    "        self.round_bets = {player.id: 0 for player in self.players}\n",
    "        self.last_raiser = None\n",
    "\n",
    "    def initialize_deck(self):\n",
    "        suits = ['h', 'd', 'c', 's']\n",
    "        ranks = list(range(2, 15))  # 2-14 where 11-14 are J, Q, K, A\n",
    "        deck = [(rank, suit) for rank in ranks for suit in suits]\n",
    "        random.shuffle(deck)\n",
    "        return deck\n",
    "\n",
    "    def deal_hole_cards(self):\n",
    "        for player in self.players:\n",
    "            player.hand = [self.deck.pop(), self.deck.pop()]\n",
    "            player.current_bet = 0\n",
    "            player.folded = False\n",
    "        self.round_bets = {player.id: 0 for player in self.players}\n",
    "\n",
    "    def post_blinds(self):\n",
    "        small_blind_player = self.players[(self.dealer_index + 1) % len(self.players)]\n",
    "        big_blind_player = self.players[(self.dealer_index + 2) % len(self.players)]\n",
    "        self._post_blind(small_blind_player, self.small_blind)\n",
    "        self._post_blind(big_blind_player, self.big_blind)\n",
    "        self.current_bet = self.big_blind\n",
    "        self.last_raiser = big_blind_player.id\n",
    "        self.current_player_index = (self.dealer_index + 3) % len(self.players)\n",
    "\n",
    "    def _post_blind(self, player, amount):\n",
    "        player.stack -= amount\n",
    "        player.current_bet = amount\n",
    "        self.pot += amount\n",
    "        self.round_bets[player.id] += amount\n",
    "\n",
    "    def get_current_player(self):\n",
    "        while True:\n",
    "            player = self.players[self.current_player_index]\n",
    "            if not player.folded and player.stack > 0:\n",
    "                return player\n",
    "            self.current_player_index = (self.current_player_index + 1) % len(self.players)\n",
    "\n",
    "    def get_available_actions(self, player):\n",
    "        actions = []\n",
    "        if player.current_bet < self.current_bet:\n",
    "            actions.extend([Action.FOLD, Action.CALL])\n",
    "            if player.stack > (self.current_bet - player.current_bet):\n",
    "                actions.append(Action.RAISE)\n",
    "        else:\n",
    "            actions.append(Action.CHECK)\n",
    "            if player.stack > 0:\n",
    "                actions.append(Action.BET)\n",
    "        return actions\n",
    "\n",
    "    def execute_action(self, player, action, raise_amount=0):\n",
    "        if action == Action.FOLD:\n",
    "            self.handle_fold(player)\n",
    "        elif action == Action.CHECK:\n",
    "            self.handle_check(player)\n",
    "        elif action == Action.CALL:\n",
    "            self.handle_call(player)\n",
    "        elif action == Action.BET:\n",
    "            self.handle_bet(player, raise_amount)\n",
    "        elif action == Action.RAISE:\n",
    "            self.handle_raise(player, raise_amount)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action\")\n",
    "\n",
    "        # Move to the next player\n",
    "        self.current_player_index = (self.current_player_index + 1) % len(self.players)\n",
    "\n",
    "    def handle_fold(self, player):\n",
    "        player.folded = True\n",
    "\n",
    "    def handle_check(self, player):\n",
    "        pass  # No action needed\n",
    "\n",
    "    def handle_call(self, player):\n",
    "        call_amount = self.current_bet - player.current_bet\n",
    "        actual_call = min(call_amount, player.stack)\n",
    "        player.stack -= actual_call\n",
    "        player.current_bet += actual_call\n",
    "        self.pot += actual_call\n",
    "        self.round_bets[player.id] += actual_call\n",
    "\n",
    "    def handle_bet(self, player, amount):\n",
    "        if amount <= 0 or amount > player.stack:\n",
    "            raise ValueError(\"Invalid bet amount\")\n",
    "        player.stack -= amount\n",
    "        player.current_bet += amount\n",
    "        self.current_bet = player.current_bet\n",
    "        self.pot += amount\n",
    "        self.round_bets[player.id] += amount\n",
    "        self.last_raiser = player.id\n",
    "\n",
    "    def handle_raise(self, player, amount):\n",
    "        if amount <= 0 or amount > player.stack:\n",
    "            raise ValueError(\"Invalid raise amount\")\n",
    "        raise_amount = amount\n",
    "        call_amount = self.current_bet - player.current_bet\n",
    "        total_bet = call_amount + raise_amount\n",
    "        if total_bet > player.stack:\n",
    "            total_bet = player.stack\n",
    "        player.stack -= total_bet\n",
    "        player.current_bet += total_bet\n",
    "        self.current_bet = player.current_bet\n",
    "        self.pot += total_bet\n",
    "        self.round_bets[player.id] += total_bet\n",
    "        self.last_raiser = player.id\n",
    "\n",
    "    def is_round_over(self):\n",
    "        active_players = [p for p in self.players if not p.folded and p.stack > 0]\n",
    "        if len(active_players) <= 1:\n",
    "            return True\n",
    "        for player in active_players:\n",
    "            if player.current_bet != self.current_bet:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def progress_round(self):\n",
    "        for player in self.players:\n",
    "            player.current_bet = 0\n",
    "        self.round_bets = {player.id: 0 for player in self.players}\n",
    "        self.current_bet = 0\n",
    "        self.last_raiser = None\n",
    "\n",
    "        if self.betting_round == 'pre-flop':\n",
    "            self.deal_flop()\n",
    "            self.betting_round = 'flop'\n",
    "        elif self.betting_round == 'flop':\n",
    "            self.deal_turn()\n",
    "            self.betting_round = 'turn'\n",
    "        elif self.betting_round == 'turn':\n",
    "            self.deal_river()\n",
    "            self.betting_round = 'river'\n",
    "        elif self.betting_round == 'river':\n",
    "            self.game_over = True\n",
    "\n",
    "    def deal_flop(self):\n",
    "        self.deck.pop()  # Burn card\n",
    "        self.board.extend([self.deck.pop() for _ in range(3)])\n",
    "\n",
    "    def deal_turn(self):\n",
    "        self.deck.pop()  # Burn card\n",
    "        self.board.append(self.deck.pop())\n",
    "\n",
    "    def deal_river(self):\n",
    "        self.deck.pop()  # Burn card\n",
    "        self.board.append(self.deck.pop())\n",
    "\n",
    "    def is_game_over(self):\n",
    "        active_players = [p for p in self.players if not p.folded and p.stack > 0]\n",
    "        if len(active_players) <= 1:\n",
    "            return True\n",
    "        return self.game_over\n",
    "\n",
    "    def determine_winner(self):\n",
    "        active_players = [p for p in self.players if not p.folded]\n",
    "        if len(active_players) == 1:\n",
    "            winner = active_players[0]\n",
    "            winner.stack += self.pot\n",
    "            self.pot = 0\n",
    "        else:\n",
    "            # Showdown: evaluate hands\n",
    "            from treys import Evaluator, Card\n",
    "            evaluator = Evaluator()\n",
    "            best_rank = None\n",
    "            winners = []\n",
    "            for player in active_players:\n",
    "                player_cards = [Card.new(f\"{self.rank_to_str(rank)}{suit}\") for rank, suit in player.hand]\n",
    "                board_cards = [Card.new(f\"{self.rank_to_str(rank)}{suit}\") for rank, suit in self.board]\n",
    "                hand_rank = evaluator.evaluate(board_cards, player_cards)\n",
    "                if best_rank is None or hand_rank < best_rank:\n",
    "                    best_rank = hand_rank\n",
    "                    winners = [player]\n",
    "                elif hand_rank == best_rank:\n",
    "                    winners.append(player)\n",
    "            split_pot = self.pot / len(winners)\n",
    "            for winner in winners:\n",
    "                winner.stack += split_pot\n",
    "            self.pot = 0\n",
    "\n",
    "    def rank_to_str(self, rank):\n",
    "        rank_dict = {14: 'A', 13: 'K', 12: 'Q', 11: 'J', 10: 'T'}\n",
    "        return rank_dict.get(rank, str(rank))\n",
    "\n",
    "    def get_reward(self, player):\n",
    "        initial_stack = 1000\n",
    "        return player.stack - initial_stack\n",
    "\n",
    "class BeliefState:\n",
    "    def __init__(self, observed_actions, public_cards, pot_size=0):\n",
    "        self.observed_actions = observed_actions\n",
    "        self.public_cards = public_cards\n",
    "        self.pot_size = pot_size  # Add pot size\n",
    "\n",
    "    def update(self, action, new_public_cards, pot_size):\n",
    "        self.observed_actions.append(action)\n",
    "        self.public_cards = new_public_cards\n",
    "        self.pot_size = pot_size\n",
    "\n",
    "def extract_features(belief_state):\n",
    "    features = []\n",
    "\n",
    "    # Encode observed actions\n",
    "    action_encoding = {\n",
    "        Action.FOLD: 0,\n",
    "        Action.CHECK: 1,\n",
    "        Action.CALL: 2,\n",
    "        Action.RAISE: 3,\n",
    "        Action.BET: 4\n",
    "    }\n",
    "    max_history_length = 12  # Increased from 10 to 12\n",
    "    action_features = [action_encoding[action] for action in belief_state.observed_actions[-max_history_length:]]\n",
    "    action_features += [0] * (max_history_length - len(action_features))\n",
    "    features.extend(action_features)\n",
    "\n",
    "    # Encode public cards\n",
    "    rank_encoding = {r: i for i, r in enumerate(range(2, 15), start=1)}\n",
    "    suit_encoding = {'h': 0, 'd': 1, 'c': 2, 's': 3}\n",
    "    max_board_cards = 6  # Increased from 5 to 6\n",
    "    board_features = []\n",
    "    for rank, suit in belief_state.public_cards:\n",
    "        rank_feature = rank_encoding.get(rank, 0)\n",
    "        suit_feature = suit_encoding.get(suit, 0)\n",
    "        board_features.extend([rank_feature, suit_feature])\n",
    "    while len(board_features) < max_board_cards * 2:\n",
    "        board_features.extend([0, 0])\n",
    "    features.extend(board_features)\n",
    "\n",
    "    # Ensure total feature length is 25\n",
    "    # Current length: max_history_length (12) + max_board_cards * 2 (12) = 24\n",
    "    # Add one more feature, e.g., pot size\n",
    "    pot_size = belief_state.pot_size if hasattr(belief_state, 'pot_size') else 0\n",
    "    features.append(pot_size / 1000)  # Normalize pot size\n",
    "\n",
    "    # Convert to tensor\n",
    "    features = torch.tensor(features, dtype=torch.float32)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jasje\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed episode 100/500\n",
      "Completed episode 200/500\n",
      "Completed episode 300/500\n",
      "Completed episode 400/500\n",
      "Completed episode 500/500\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from enum import Enum, auto\n",
    "\n",
    "class Action(Enum):\n",
    "    FOLD = 0\n",
    "    CHECK = 1\n",
    "    CALL = 2\n",
    "    RAISE = 3\n",
    "    BET = 4\n",
    "\n",
    "# Define MAX_FEATURE_LENGTH\n",
    "MAX_FEATURE_LENGTH = 25  # Adjust as needed\n",
    "\n",
    "# Define sample_action function\n",
    "def sample_action(action_probs, valid_actions):\n",
    "    \"\"\"\n",
    "    Samples an action from the given action probabilities, considering only valid actions.\n",
    "\n",
    "    Args:\n",
    "        action_probs (torch.Tensor): A tensor containing the probabilities for each action.\n",
    "        valid_actions (list of Action): List of valid actions in the current state.\n",
    "\n",
    "    Returns:\n",
    "        Action: The selected action.\n",
    "    \"\"\"\n",
    "    action_list = list(Action)\n",
    "    action_to_index = {action: idx for idx, action in enumerate(action_list)}\n",
    "    valid_action_indices = [action_to_index[action] for action in valid_actions]\n",
    "\n",
    "    # Get probabilities of valid actions\n",
    "    valid_action_probs = action_probs[valid_action_indices]\n",
    "    valid_action_probs /= valid_action_probs.sum()  # Normalize\n",
    "\n",
    "    # Sample from valid actions\n",
    "    chosen_index = torch.multinomial(valid_action_probs, num_samples=1).item()\n",
    "    selected_action = valid_actions[chosen_index]\n",
    "\n",
    "    return selected_action\n",
    "\n",
    "def determine_raise_amount(player, game):\n",
    "    \"\"\"\n",
    "    Determines the amount to raise or bet.\n",
    "\n",
    "    Args:\n",
    "        player (Player): The player who is raising.\n",
    "        game (TexasHoldEm): The current game state.\n",
    "\n",
    "    Returns:\n",
    "        float: The raise amount.\n",
    "    \"\"\"\n",
    "    # Simple strategy: raise by a fixed amount or percentage of the pot\n",
    "    # For this example, we'll raise by half the pot or the player's remaining stack, whichever is smaller\n",
    "    raise_amount = min(player.stack, max(game.pot * 0.5, game.big_blind))\n",
    "    return raise_amount\n",
    "\n",
    "# Initialize neural networks and optimizers\n",
    "value_net = ValueNetwork(input_size=MAX_FEATURE_LENGTH)\n",
    "policy_net = PolicyNetwork(input_size=MAX_FEATURE_LENGTH, action_space=len(Action))\n",
    "value_optimizer = optim.Adam(value_net.parameters(), lr=1e-4)\n",
    "policy_optimizer = optim.Adam(policy_net.parameters(), lr=1e-4)\n",
    "\n",
    "NUM_EPISODES = 500\n",
    "\n",
    "# Training loop\n",
    "for episode in range(NUM_EPISODES):\n",
    "    # Initialize players\n",
    "    players = [Player(id=0, stack=1000), Player(id=1, stack=1000)]\n",
    "    \n",
    "    # Initialize the game\n",
    "    game = TexasHoldEm(players)\n",
    "    game.deal_hole_cards()\n",
    "    game.post_blinds()\n",
    "    \n",
    "    # Initialize belief states for each player\n",
    "    belief_states = {\n",
    "        player.id: BeliefState(\n",
    "            observed_actions=[],\n",
    "            public_cards=game.board,\n",
    "            pot_size=game.pot  # Optional\n",
    "        ) for player in players\n",
    "    }\n",
    "    \n",
    "    done = False\n",
    "    experiences = {player.id: [] for player in players}  # Collect experiences for each player separately\n",
    "    \n",
    "    while not done:\n",
    "        current_player = game.get_current_player()\n",
    "        belief_state = belief_states[current_player.id]\n",
    "        \n",
    "        # Extract features\n",
    "        features = extract_features(belief_state)\n",
    "\n",
    "        # Ensure features have the correct shape\n",
    "        if features.dim() == 1:\n",
    "            features = features.unsqueeze(0)  # Add batch dimension if necessary\n",
    "        \n",
    "        # Get action probabilities from the policy network\n",
    "        action_probs = policy_net(features)\n",
    "        action_probs = action_probs.squeeze(0)  # Remove batch dimension\n",
    "        \n",
    "        # Get available actions for the current player\n",
    "        valid_actions = game.get_available_actions(current_player)\n",
    "        \n",
    "        # Choose an action\n",
    "        action = sample_action(action_probs, valid_actions)\n",
    "        \n",
    "        # Determine raise amount if necessary\n",
    "        if action in [Action.BET, Action.RAISE]:\n",
    "            raise_amount = determine_raise_amount(current_player, game)\n",
    "            game.execute_action(current_player, action, raise_amount=raise_amount)\n",
    "        else:\n",
    "            game.execute_action(current_player, action)\n",
    "        \n",
    "        # Record experience for the current player\n",
    "        experiences[current_player.id].append((features.squeeze(0), action, 0))  # Squeeze features before storing, and reward is zero for now\n",
    "        \n",
    "        # Update belief states for all players\n",
    "        for player in players:\n",
    "            belief_states[player.id].update(\n",
    "                action,\n",
    "                new_public_cards=game.board,\n",
    "                pot_size=game.pot  # Add this argument\n",
    "            )\n",
    "        \n",
    "        # Check for end of round/game\n",
    "        if game.is_round_over():\n",
    "            game.progress_round()\n",
    "        if game.is_game_over():\n",
    "            game.determine_winner()\n",
    "            done = True  # End the game loop\n",
    "    \n",
    "    # After the game ends, assign rewards and update networks\n",
    "    \n",
    "    # Assign final rewards to each player's experiences\n",
    "    # Update belief states for all players\n",
    "    for player in players:\n",
    "        belief_states[player.id].update(\n",
    "            action,\n",
    "            new_public_cards=game.board,\n",
    "            pot_size=game.pot\n",
    "        )\n",
    "    \n",
    "    # Combine experiences from both players\n",
    "    all_experiences = []\n",
    "    for exp_list in experiences.values():\n",
    "        all_experiences.extend(exp_list)\n",
    "    \n",
    "    # Proceed to prepare data and update networks\n",
    "\n",
    "    # Step 1: Prepare the training data\n",
    "    states = torch.stack([exp[0] for exp in all_experiences])  # Features are tensors\n",
    "    actions = [exp[1] for exp in all_experiences]              # Actions are enums\n",
    "    rewards = [exp[2] for exp in all_experiences]              # Rewards are scalars\n",
    "\n",
    "    # Step 2: Convert actions to indices\n",
    "    action_to_index = {action: idx for idx, action in enumerate(Action)}\n",
    "    action_indices = torch.tensor([action_to_index[action] for action in actions], dtype=torch.long)\n",
    "\n",
    "    # Step 3: Compute value targets\n",
    "    value_targets = torch.tensor(rewards, dtype=torch.float32)\n",
    "    \n",
    "    # Step 4: Compute value loss\n",
    "    value_predictions = value_net(states).squeeze()\n",
    "    value_loss_fn = nn.MSELoss()\n",
    "    value_loss = value_loss_fn(value_predictions, value_targets)\n",
    "\n",
    "    # Step 5: Compute policy loss\n",
    "    policy_outputs = policy_net(states)  # Shape: (batch_size, num_actions)\n",
    "    \n",
    "    action_probs_taken = policy_outputs.gather(1, action_indices.unsqueeze(1)).squeeze()\n",
    "    log_probs = torch.log(action_probs_taken + 1e-10)\n",
    "    with torch.no_grad():\n",
    "        advantages = value_targets - value_predictions.detach()\n",
    "    policy_loss = - (log_probs * advantages).mean()\n",
    "    \n",
    "    # Optional: Add entropy regularization to encourage exploration\n",
    "    entropy = - (policy_outputs * torch.log(policy_outputs + 1e-10)).sum(dim=1).mean()\n",
    "    entropy_coef = 0.01  # Adjust as needed\n",
    "    policy_loss = policy_loss - entropy_coef * entropy\n",
    "\n",
    "    # Step 6: Update the networks\n",
    "    # Update value network\n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward()\n",
    "    value_optimizer.step()\n",
    "\n",
    "    # Update policy network\n",
    "    policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "    \n",
    "    # Optionally, print progress\n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print(f\"Completed episode {episode + 1}/{NUM_EPISODES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training is complete\n",
    "torch.save(policy_net.state_dict(), 'policy_net.pth')\n",
    "torch.save(value_net.state_dict(), 'value_net.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
